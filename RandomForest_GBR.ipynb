{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4df8016e0cc4f27ebf4e0f8ff4b04491",
     "grade": false,
     "grade_id": "cell-dcd93d4a72bf07f7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# IST 718: Big Data Analytics\n",
    "\n",
    "- Professor: Daniel Acuna <deacuna@syr.edu>\n",
    "\n",
    "## General instructions:\n",
    "\n",
    "- You are welcome to discuss the problems with your classmates but __you are not allowed to copy any part of your answers either from your classmates or from the internet__\n",
    "- You can put the homework files anywhere you want in your http://jupyterhub.ischool.syr.edu/ workspace but _do not change_ the file names. The TAs and the professor use these names to grade your homework.\n",
    "- Remove or comment out code that contains `raise NotImplementedError`. This is mainly to make the `assert` statement fail if nothing is submitted.\n",
    "- The tests shown in some cells (i.e., `assert` and `np.testing.` statements) are used to grade your answers. **However, the professor and TAs will use __additional__ test for your answer. Think about cases where your code should run even if it passess all the tests you see.**\n",
    "- Before downloading and submitting your work through Blackboard, remember to save and press `Validate` (or go to \n",
    "`Kernel`$\\rightarrow$`Restart and Run All`). \n",
    "- Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8771ab89d8f5d55a8bfd66acb59f97bb",
     "grade": false,
     "grade_id": "cell-7477f2a09341e9e4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# load these packages\n",
    "import pyspark\n",
    "from pyspark.ml import feature, classification\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import functions as fn\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import feature, regression, evaluation, Pipeline\n",
    "from pyspark.sql import functions as fn, Row\n",
    "import matplotlib.pyplot as plt\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d56dff7ce693eb60fd342ac3828746a0",
     "grade": false,
     "grade_id": "cell-5e8710281af9d99d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Part 1: Random Forest and gradient boosted trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f4dbf09ebe769340577b3d340f005634",
     "grade": false,
     "grade_id": "cell-4ea7be104cf9c682",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In these questions, we will examine the famous [Auto dataset](https://vincentarelbundock.github.io/Rdatasets/doc/ISLR/Auto.html). With this dataset, the goal is to predict the miles per gallon (`mpg`) performance based on characteristics of the car such as number of cylinders (`cylinders`), displacement between wheels (`displacement`), horsepower of the engine (`horsepower`), weight of the car (`weight`), top acceleration (`acceleration`), year of the model (`year`), and origin (`origin`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "20+10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- mpg: double (nullable = true)\n",
      " |-- cylinders: integer (nullable = true)\n",
      " |-- displacement: double (nullable = true)\n",
      " |-- weight: integer (nullable = true)\n",
      " |-- acceleration: double (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- origin: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- horsepower: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read-only\n",
    "mpg_df = spark.read.csv('Auto.csv', header=True, inferSchema=True).\\\n",
    "    drop('_c0').\\\n",
    "    withColumn('horsepower2', fn.col('horsepower').cast('int')).\\\n",
    "    drop('horsepower').\\\n",
    "    withColumnRenamed('horsepower2', 'horsepower').\\\n",
    "    dropna()\n",
    "training_df, validation_df, testing_df = mpg_df.randomSplit([0.6, 0.3, 0.1], seed=0)\n",
    "mpg_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c64f5d294a617c3c9d97f056c1a95cbf",
     "grade": false,
     "grade_id": "cell-b759b0bebcd5bff5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Question 1: (15 pts)\n",
    "\n",
    "Create three pipelines that contain three different random forests and take in all features from `mpg_df` (`cylinders`, `displacement`, `horsepower`, `weight`, `acceleration`, `year`, and `origin`) to predict (`mpg`). **Set the `seed` parameter of the random forest to 0.** Fit these pipelines to the training data (`training_df`):\n",
    "\n",
    "- `pipe_rf1`: Random forest with `maxDepth=2` and `numTrees=60`\n",
    "- `pipe_rf2`: Random forest with `maxDepth=3` and `numTrees=40`\n",
    "- `pipe_rf3`: Random forest with `maxDepth=6`, `numTrees=20`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0046b3ab912f7c65375159cff70a1f4f",
     "grade": false,
     "grade_id": "cell-e979ecd04e65bbd0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# create the fitted pipelines `pipe_rf1`, `pipe_rf2`, and `pipe_rf3` here\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "# set input/output columns\n",
    "input_cols = ['cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'year', 'origin']\n",
    "va = feature.VectorAssembler(inputCols=input_cols, outputCol='features')\n",
    "\n",
    "# set RandomForest configurations\n",
    "rf1 = regression.RandomForestRegressor(\n",
    "    labelCol='mpg', \n",
    "    featuresCol='features', \n",
    "    maxDepth=2, \n",
    "    numTrees=60, \n",
    "    seed=0)\n",
    "rf2 = regression.RandomForestRegressor(\n",
    "    labelCol='mpg', \n",
    "    featuresCol='features', \n",
    "    maxDepth=3, \n",
    "    numTrees=40, \n",
    "    seed=0)\n",
    "rf3 = regression.RandomForestRegressor(\n",
    "    labelCol='mpg', \n",
    "    featuresCol='features', \n",
    "    maxDepth=6, \n",
    "    numTrees=20, \n",
    "    seed=0)\n",
    "\n",
    "# Create pipelines\n",
    "pipe_1 = Pipeline(stages=[va, rf1]) \n",
    "pipe_2 = Pipeline(stages=[va, rf2]) \n",
    "pipe_3 = Pipeline(stages=[va, rf3]) \n",
    "\n",
    "# fit data to pipelines\n",
    "pipe_rf1 = pipe_1.fit(training_df) \n",
    "pipe_rf2 = pipe_2.fit(training_df) \n",
    "pipe_rf3 = pipe_3.fit(training_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ef1f7c5f88fc87738c6d9d997fabc91d",
     "grade": true,
     "grade_id": "cell-1b42b9d0c01a4e99",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# tests for 10 pts\n",
    "np.testing.assert_equal(type(pipe_rf1.stages[0]), feature.VectorAssembler)\n",
    "np.testing.assert_equal(type(pipe_rf2.stages[0]), feature.VectorAssembler)\n",
    "np.testing.assert_equal(type(pipe_rf3.stages[0]), feature.VectorAssembler)\n",
    "np.testing.assert_equal(type(pipe_rf1.stages[1]), regression.RandomForestRegressionModel)\n",
    "np.testing.assert_equal(type(pipe_rf2.stages[1]), regression.RandomForestRegressionModel)\n",
    "np.testing.assert_equal(type(pipe_rf3.stages[1]), regression.RandomForestRegressionModel)\n",
    "np.testing.assert_equal(type(pipe_rf1.transform(training_df)), pyspark.sql.dataframe.DataFrame)\n",
    "np.testing.assert_equal(type(pipe_rf2.transform(training_df)), pyspark.sql.dataframe.DataFrame)\n",
    "np.testing.assert_equal(type(pipe_rf3.transform(training_df)), pyspark.sql.dataframe.DataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b5ff7d4f3bfae48ef96a76311631358e",
     "grade": false,
     "grade_id": "cell-aea2a73f42aa014c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Question 2 (10 pts)\n",
    "\n",
    "Use the following evaluator to compute the $R^2$ of the models on validation data. Assign the $R^2$ of the three models to `R2_1`, `R2_2`, and `R2_3`, respectively, and the performance. Assign the best pipeline based on validation performance to a variable `best_model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = evaluation.RegressionEvaluator(labelCol='mpg', metricName='r2')\n",
    "# use it as follows:\n",
    "#   evaluator.evaluate(fitted_pipeline.transform(df)) -> R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bf22d0736146193218983d337260aff5",
     "grade": false,
     "grade_id": "cell-b27f89932b355aba",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R squared for each model (higher is better): \n",
      "pipe 1:  0.7858069247875485 \n",
      "pipe 2:  0.8222168008753123 \n",
      "pipe 3:  0.8833324964226545\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "R2_1 = evaluator.evaluate(pipe_rf1.transform(validation_df))\n",
    "R2_2 = evaluator.evaluate(pipe_rf2.transform(validation_df))\n",
    "R2_3 = evaluator.evaluate(pipe_rf3.transform(validation_df))\n",
    "\n",
    "print(\n",
    "    'R squared for each model (higher is better):',\n",
    "    '\\npipe 1: ', R2_1,\n",
    "    '\\npipe 2: ', R2_2,\n",
    "    '\\npipe 3: ', R2_3\n",
    ")\n",
    "best_model = pipe_rf3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "08beedb88eaeb7a72741418debc60295",
     "grade": true,
     "grade_id": "cell-10f241cc1a17f246",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# tests for 10 pts\n",
    "np.testing.assert_equal(type(best_model.stages[0]), feature.VectorAssembler)\n",
    "np.testing.assert_equal(type(best_model.stages[1]), regression.RandomForestRegressionModel)\n",
    "np.testing.assert_equal(type(best_model.transform(validation_df)), pyspark.sql.dataframe.DataFrame)\n",
    "np.testing.assert_array_less(R2_1, 1.)\n",
    "np.testing.assert_array_less(0.5, R2_1)\n",
    "np.testing.assert_array_less(R2_2, 1.)\n",
    "np.testing.assert_array_less(0.5, R2_2)\n",
    "np.testing.assert_array_less(R2_3, 1.)\n",
    "np.testing.assert_array_less(0.5, R2_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "626382c570f27341e0d842f074946c04",
     "grade": false,
     "grade_id": "cell-f2ad76e4a06d8158",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Question 3: 5 pts\n",
    "\n",
    "Compute the $R^2$ of the model on testing data, print it, and assign it to variable `R2_best`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "59af342cf4b88e6807d2998ab6e5173a",
     "grade": false,
     "grade_id": "cell-8d0a993a398b9a9e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R squared for each model on test data: \n",
      "pipe 1:  0.6523842125009692 \n",
      "pipe 2:  0.7359133602778649 \n",
      "pipe 3:  0.8116746291631238\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "R2_1 = evaluator.evaluate(pipe_rf1.transform(testing_df))\n",
    "R2_2 = evaluator.evaluate(pipe_rf2.transform(testing_df))\n",
    "R2_3 = evaluator.evaluate(pipe_rf3.transform(testing_df))\n",
    "\n",
    "print(\n",
    "    'R squared for each model on test data:',\n",
    "    '\\npipe 1: ', R2_1,\n",
    "    '\\npipe 2: ', R2_2,\n",
    "    '\\npipe 3: ', R2_3\n",
    ")\n",
    "\n",
    "R2_best = R2_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f52f540d80d96fe973e38b1dfd9dcc6c",
     "grade": true,
     "grade_id": "cell-4a2bc953fbc2f723",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# tests for 5 pts\n",
    "np.testing.assert_array_less(R2_best, 1.)\n",
    "np.testing.assert_array_less(0.6, R2_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c2aa30c46bab90f68eb0cd4417fac47c",
     "grade": false,
     "grade_id": "cell-cba15c893401c9fb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Question 4: 5 pts\n",
    "\n",
    "Using the parameters of the best model, create a new pipeline called `final_model` and fit it to the entire data (`mpg_df`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d2f69942fbccbbe6d7e0cb77fbbbb10d",
     "grade": false,
     "grade_id": "cell-26de3c4544c3b2d7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# create the fitted pipeline `final_model` here\n",
    "# YOUR CODE HERE\n",
    "final_model = pipe_3.fit(mpg_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8d077f5b32815657372d6249f290eaad",
     "grade": true,
     "grade_id": "cell-19829d6a93ff99d0",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# tests for 10 pts\n",
    "np.testing.assert_equal(type(final_model.stages[0]), feature.VectorAssembler)\n",
    "np.testing.assert_equal(type(final_model.stages[1]), regression.RandomForestRegressionModel)\n",
    "np.testing.assert_equal(type(final_model.transform(mpg_df)), pyspark.sql.dataframe.DataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b65963d25f282944e2057eb6f38f8c2a",
     "grade": false,
     "grade_id": "cell-db637392290a8b68",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Question 5: 15 pts\n",
    "\n",
    "Create a pandas dataframe `feature_importance` with the columns `feature` and `importance` which contains all the names of the features (`cylinder`, `displacement`, etc.) and their feature importances as determined by the random forest of the final model. Sort the dataframe by `importance` in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "254ae9ef95403f6e24b49c72ffa837c6",
     "grade": false,
     "grade_id": "cell-4c119d3de2edc639",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# create feature_importance below\n",
    "# YOUR CODE HERE\n",
    "feature_importance = pd.DataFrame(\n",
    "    list(zip(input_cols,\n",
    "            final_model.stages[-1].featureImportances.toArray()\n",
    "        )),\n",
    "    columns=['feature','importance'])\n",
    "\n",
    "feature_importance = feature_importance.sort_values(\n",
    "    'importance', \n",
    "    ascending=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>displacement</td>\n",
       "      <td>0.379758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>horsepower</td>\n",
       "      <td>0.172883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>weight</td>\n",
       "      <td>0.143796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cylinders</td>\n",
       "      <td>0.134298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>year</td>\n",
       "      <td>0.133876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>acceleration</td>\n",
       "      <td>0.024922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>origin</td>\n",
       "      <td>0.010467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        feature  importance\n",
       "1  displacement    0.379758\n",
       "2    horsepower    0.172883\n",
       "3        weight    0.143796\n",
       "0     cylinders    0.134298\n",
       "5          year    0.133876\n",
       "4  acceleration    0.024922\n",
       "6        origin    0.010467"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display it here\n",
    "feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d54cccd8afa23f8e7a56dbe05885d457",
     "grade": true,
     "grade_id": "cell-abc93dd0d7d0f791",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# tests for 5 pts\n",
    "assert type(feature_importance) == pd.core.frame.DataFrame\n",
    "np.testing.assert_array_equal(list(feature_importance.columns), ['feature', 'importance'])\n",
    "np.testing.assert_array_equal(list(feature_importance.columns), ['feature', 'importance'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(10 pts)** Comment below on the importance that random forest has given to each feature. Are they reasonable? Do they tell you anything valuable about the mpg dataset? Answer in the cell below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7e98bc9ea4757436cc983a756ad906f2",
     "grade": true,
     "grade_id": "cell-091662aeec14bd5f",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "The answers are reasonable. It makes sense that where a car comes from doesn't have much affect on their fuel efficiency, and the displacement, or distance between the wheels has a large effect on mileage as it's a physical feature that probably is related to aerodynamics. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5b2dd95411be00745762f4e323c98c93",
     "grade": false,
     "grade_id": "cell-224ea03993b0aa23",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Question 6:  10 pts.\n",
    "\n",
    "Pick any of the trees from the final model and assign its `toDebugString` property to a variable `example_tree`. Print this variable and **add comments** to the cell describing how you think this particular tree is fitting the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0ab13e8be21f0efe15c3ddb740ed50cc",
     "grade": false,
     "grade_id": "cell-6198242644034d69",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'year', 'origin']\n",
      "DecisionTreeRegressionModel: uid=dtr_41cc81d6d670, depth=6, numNodes=101, numFeatures=7\n",
      "  If (feature 0 <= 5.5)\n",
      "   If (feature 3 <= 2224.5)\n",
      "    If (feature 4 <= 14.350000000000001)\n",
      "     If (feature 1 <= 79.5)\n",
      "      Predict: 18.0\n",
      "     Else (feature 1 > 79.5)\n",
      "      If (feature 5 <= 77.5)\n",
      "       If (feature 6 <= 1.5)\n",
      "        Predict: 23.0\n",
      "       Else (feature 6 > 1.5)\n",
      "        Predict: 29.25\n",
      "      Else (feature 5 > 77.5)\n",
      "       If (feature 3 <= 1947.5)\n",
      "        Predict: 31.9\n",
      "       Else (feature 3 > 1947.5)\n",
      "        Predict: 33.96\n",
      "    Else (feature 4 > 14.350000000000001)\n",
      "     If (feature 6 <= 2.5)\n",
      "      If (feature 5 <= 77.5)\n",
      "       If (feature 5 <= 76.5)\n",
      "        Predict: 27.863636363636363\n",
      "       Else (feature 5 > 76.5)\n",
      "        Predict: 31.875\n",
      "      Else (feature 5 > 77.5)\n",
      "       If (feature 2 <= 53.5)\n",
      "        Predict: 43.325\n",
      "       Else (feature 2 > 53.5)\n",
      "        Predict: 35.24545454545454\n",
      "     Else (feature 6 > 2.5)\n",
      "      If (feature 3 <= 2047.5)\n",
      "       If (feature 5 <= 76.5)\n",
      "        Predict: 31.818181818181817\n",
      "       Else (feature 5 > 76.5)\n",
      "        Predict: 35.50769230769231\n",
      "      Else (feature 3 > 2047.5)\n",
      "       If (feature 1 <= 89.5)\n",
      "        Predict: 42.44285714285714\n",
      "       Else (feature 1 > 89.5)\n",
      "        Predict: 32.97500000000001\n",
      "   Else (feature 3 > 2224.5)\n",
      "    If (feature 2 <= 84.5)\n",
      "     If (feature 2 <= 75.5)\n",
      "      If (feature 6 <= 1.5)\n",
      "       If (feature 1 <= 107.5)\n",
      "        Predict: 30.1\n",
      "       Else (feature 1 > 107.5)\n",
      "        Predict: 25.75\n",
      "      Else (feature 6 > 1.5)\n",
      "       If (feature 0 <= 4.5)\n",
      "        Predict: 31.41666666666667\n",
      "       Else (feature 0 > 4.5)\n",
      "        Predict: 36.400000000000006\n",
      "     Else (feature 2 > 75.5)\n",
      "      If (feature 5 <= 81.5)\n",
      "       If (feature 4 <= 12.95)\n",
      "        Predict: 30.0\n",
      "       Else (feature 4 > 12.95)\n",
      "        Predict: 26.39230769230769\n",
      "      Else (feature 5 > 81.5)\n",
      "       If (feature 4 <= 13.1)\n",
      "        Predict: 33.333333333333336\n",
      "       Else (feature 4 > 13.1)\n",
      "        Predict: 29.0\n",
      "    Else (feature 2 > 84.5)\n",
      "     If (feature 6 <= 1.5)\n",
      "      If (feature 5 <= 78.5)\n",
      "       If (feature 2 <= 87.5)\n",
      "        Predict: 20.0\n",
      "       Else (feature 2 > 87.5)\n",
      "        Predict: 23.77777777777778\n",
      "      Else (feature 5 > 78.5)\n",
      "       If (feature 3 <= 2589.5)\n",
      "        Predict: 33.125\n",
      "       Else (feature 3 > 2589.5)\n",
      "        Predict: 26.592307692307696\n",
      "     Else (feature 6 > 1.5)\n",
      "      If (feature 5 <= 78.5)\n",
      "       If (feature 3 <= 2715.5)\n",
      "        Predict: 24.28518518518519\n",
      "       Else (feature 3 > 2715.5)\n",
      "        Predict: 21.15625\n",
      "      Else (feature 5 > 78.5)\n",
      "       If (feature 2 <= 90.5)\n",
      "        Predict: 29.8\n",
      "       Else (feature 2 > 90.5)\n",
      "        Predict: 32.449999999999996\n",
      "  Else (feature 0 > 5.5)\n",
      "   If (feature 5 <= 74.5)\n",
      "    If (feature 3 <= 3462.0)\n",
      "     If (feature 1 <= 212.5)\n",
      "      If (feature 5 <= 70.5)\n",
      "       Predict: 18.0\n",
      "      Else (feature 5 > 70.5)\n",
      "       Predict: 20.75\n",
      "     Else (feature 1 > 212.5)\n",
      "      If (feature 4 <= 16.55)\n",
      "       If (feature 3 <= 3412.5)\n",
      "        Predict: 17.818181818181817\n",
      "       Else (feature 3 > 3412.5)\n",
      "        Predict: 16.4\n",
      "      Else (feature 4 > 16.55)\n",
      "       Predict: 15.0\n",
      "    Else (feature 3 > 3462.0)\n",
      "     If (feature 4 <= 16.299999999999997)\n",
      "      If (feature 3 <= 4159.5)\n",
      "       If (feature 5 <= 73.5)\n",
      "        Predict: 14.380952380952381\n",
      "       Else (feature 5 > 73.5)\n",
      "        Predict: 16.0\n",
      "      Else (feature 3 > 4159.5)\n",
      "       If (feature 1 <= 329.0)\n",
      "        Predict: 11.25\n",
      "       Else (feature 1 > 329.0)\n",
      "        Predict: 13.0\n",
      "     Else (feature 4 > 16.299999999999997)\n",
      "      Predict: 16.0\n",
      "   Else (feature 5 > 74.5)\n",
      "    If (feature 1 <= 284.5)\n",
      "     If (feature 4 <= 11.45)\n",
      "      Predict: 32.7\n",
      "     Else (feature 4 > 11.45)\n",
      "      If (feature 4 <= 18.25)\n",
      "       If (feature 5 <= 81.5)\n",
      "        Predict: 19.556818181818183\n",
      "       Else (feature 5 > 81.5)\n",
      "        Predict: 26.4\n",
      "      Else (feature 4 > 18.25)\n",
      "       If (feature 4 <= 19.55)\n",
      "        Predict: 18.671428571428574\n",
      "       Else (feature 4 > 19.55)\n",
      "        Predict: 17.0\n",
      "    Else (feature 1 > 284.5)\n",
      "     If (feature 5 <= 77.5)\n",
      "      If (feature 3 <= 4057.5)\n",
      "       If (feature 2 <= 127.0)\n",
      "        Predict: 15.5\n",
      "       Else (feature 2 > 127.0)\n",
      "        Predict: 13.0\n",
      "      Else (feature 3 > 4057.5)\n",
      "       If (feature 5 <= 76.5)\n",
      "        Predict: 16.3125\n",
      "       Else (feature 5 > 76.5)\n",
      "        Predict: 15.5\n",
      "     Else (feature 5 > 77.5)\n",
      "      If (feature 4 <= 15.45)\n",
      "       If (feature 3 <= 4057.5)\n",
      "        Predict: 18.157142857142855\n",
      "       Else (feature 3 > 4057.5)\n",
      "        Predict: 16.900000000000006\n",
      "      Else (feature 4 > 15.45)\n",
      "       Predict: 23.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create a variable example_tree with the toDebugString property of a tree from final_model.\n",
    "# print this string and comment in this same cell about the branches that this tree fit\n",
    "\n",
    "\n",
    "example_tree = final_model.stages[-1].trees[1].toDebugString\n",
    "print(final_model.stages[-2].getInputCols())\n",
    "print(example_tree)\n",
    "\n",
    "# The first branch includes observations that are equal to or less than 5.5 cylinders, equal to or less than 2224 lbs, \n",
    "# <= 14 acceleration, and the displacement is <= 79.5 where the model predicts the mpg to be 18."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ea855cbe728eac9bed8155efb1272c3a",
     "grade": true,
     "grade_id": "cell-e85b6170a6e6e815",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# tests for 5 points\n",
    "assert type(example_tree) == str\n",
    "assert 'DecisionTreeRegressionModel' in example_tree\n",
    "assert 'feature 0' in example_tree\n",
    "assert 'If' in example_tree\n",
    "assert 'Else' in example_tree\n",
    "assert 'Predict' in example_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4cd10e22e51780c1fa9856487d2903c5",
     "grade": false,
     "grade_id": "cell-06400cc49bb80e2b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# **Question 7 (10 pts)**\n",
    "\n",
    "Gradient boosted trees are becoming increasingly popular for competitions. There is a high-performance implementation, [xgboost](https://en.wikipedia.org/wiki/XGBoost), that is particularly popular. Compare gradient boosted regression to the best model found with random forest in Question 3 using the `validation set`. For GBR, use all the default parameters except make `seed=0`. Assign the pipeline and the $R^2$ of the model to `gbr_pipe` and `R2_gbr`, respectively. Does it have an amazing or dissapointing $R^2$? **Comment below**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4828679005c81607c6410e8f47ed807d",
     "grade": false,
     "grade_id": "cell-9825c25005a0abae",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# configure gradiennt boost regressor\n",
    "gradient_boost = regression.GBTRegressor(\n",
    "    labelCol='mpg',\n",
    "    featuresCol='features',\n",
    "    seed = 0)\n",
    "# create and fit pipeline\n",
    "gbr_pipe = Pipeline(stages=[va,gradient_boost]).fit(training_df)\n",
    "# evaluate model\n",
    "R2_gbr = evaluator.evaluate(gbr_pipe.transform(validation_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of best RF:  0.8833324964226545\n",
      "Performance of GBR:  0.8404903251080562\n"
     ]
    }
   ],
   "source": [
    "# test your models here\n",
    "print(\"Performance of best RF: \", evaluator.evaluate(best_model.transform(validation_df)))\n",
    "print(\"Performance of GBR: \", R2_gbr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "694f90a1f0a57bac564e643c5196535e",
     "grade": true,
     "grade_id": "cell-3ff59920f704ccc7",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# \n",
    "# It seems that the best of our RF models performed better as they had a higher R squared value than the gradient\n",
    "# boosted model on the validation data. This is disappointing, and goes to show that very rarely is there a silver bullet\n",
    "# model for every dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7dcc6c3b87298d749d2ef77c4b81a8f4",
     "grade": true,
     "grade_id": "cell-35dbd5a779c5d2ed",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# tests for 5 pts\n",
    "np.testing.assert_equal(type(gbr_pipe.stages[0]), feature.VectorAssembler)\n",
    "np.testing.assert_equal(type(gbr_pipe.stages[1]), regression.GBTRegressionModel)\n",
    "np.testing.assert_equal(type(gbr_pipe.transform(validation_df)), pyspark.sql.dataframe.DataFrame)\n",
    "np.testing.assert_array_less(R2_gbr, 1.)\n",
    "np.testing.assert_array_less(0.5, R2_gbr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
