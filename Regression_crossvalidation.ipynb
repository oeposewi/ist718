{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7da89413c16b9232417a288f5f4a90d5",
     "grade": false,
     "grade_id": "cell-b11b633c1b5945fe",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# IST 718: Big Data Analytics\n",
    "\n",
    "- Professor: Daniel Acuna <deacuna@syr.edu>\n",
    "\n",
    "## General instructions:\n",
    "\n",
    "- You are welcome to discuss the problems with your classmates but __you are not allowed to copy any part of your answers either from your classmates or from the internet__\n",
    "- You can put the homework files anywhere you want in your http://notebook.acuna.io workspace but _do not change_ the file names. The TAs and the professor use these names to grade your homework.\n",
    "- Remove or comment out code that contains `raise NotImplementedError`. This is mainly to make the `assert` statement fail if nothing is submitted.\n",
    "- The tests shown in some cells (i.e., `assert` and `np.testing.` statements) are used to grade your answers. **However, the professor and TAs will use __additional__ test for your answer. Think about cases where your code should run even if it passess all the tests you see.**\n",
    "- Before downloading and submitting your work through Blackboard, remember to save and press `Validate` (or go to \n",
    "`Kernel`$\\rightarrow$`Restart and Run All`). \n",
    "- Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3fe2047354b19195bdf5522cbf281619",
     "grade": false,
     "grade_id": "cell-018f7df76fbe7856",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Load the packages needed for this part\n",
    "# create spark and sparkcontext objects\n",
    "from pyspark.sql import SparkSession\n",
    "import numpy as np\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "import pyspark\n",
    "from pyspark.ml import feature, regression, Pipeline\n",
    "from pyspark.sql import functions as fn, Row\n",
    "from pyspark import sql\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8cf2044a50756dcbf5ea6c35bf7d42f1",
     "grade": false,
     "grade_id": "cell-baf717df615c90b2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Part 1: Admission analysis\n",
    "\n",
    "In this assignment, you will have to do an analysis on graduate admission dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a10d9c9cd49d50cafb359604a884025d",
     "grade": false,
     "grade_id": "cell-b3d0fec5fd8fa1aa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Admission data analysis\n",
    "```console\n",
    "1. Title: Graduate Admission Data\n",
    "\n",
    "2. Sources:\n",
    "    Mohan S Acharya, Asfia Armaan, Aneeta S Antony : A Comparison of Regression Models for Prediction of Graduate Admissions, IEEE International Conference on Computational Intelligence in Data Science 2019\n",
    "    \n",
    "3. Number of Instances: 400\n",
    "\n",
    "4. Numer of Attributes: 8 + numeric chance of admit \n",
    "\n",
    "5. Attribute information:\n",
    "    \n",
    "    1. Region: A,B,C,D,E\n",
    "    2. GRE_Score: out of 340\n",
    "    3. TOEFL_Scores: out of 120 \n",
    "    4. University_Rating: out of 5 \n",
    "    5. SOP (Statement of Purpose): out of 5\n",
    "    6. LOR (Letter of Recommendation): out of 5 \n",
    "    7. CGPA (Undergraduate GPA): out of 10 \n",
    "    8. Research (Research Experience): either 0 or 1 \n",
    "    9. Chance_of_Admit: ranging from 0 to 1 \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ba156df7460502db19587cedd3920ffd",
     "grade": false,
     "grade_id": "cell-fbd13f1a46d7ab58",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "admission_df = spark.createDataFrame(pd.read_csv('Admission_Predict.csv', sep=','))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6101064f7058d337cfc70fd28780d64e",
     "grade": false,
     "grade_id": "cell-7a1ec8f49ea0c803",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# 1. Explore the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With big data, datasets can be too big to bring them into the Spark client. However, we can use the `limit` method of a dataframe to limit the number of rows to bring as a Pandas dataframe.\n",
    "\n",
    "Create a dataframe `admission_sample_df` with the first 30 rows of `admission_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e89e882063996b7dab8a5242e3929d2b",
     "grade": false,
     "grade_id": "cell-e80e04372b503a3e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Region='C', GRE_Score=337, TOEFL_Score=118, University_Rating=4, SOP=4.5, LOR=4.5, CGPA=9.65, Research=1, Chance_of_Admit=0.92),\n",
       " Row(Region='E', GRE_Score=324, TOEFL_Score=107, University_Rating=4, SOP=4.0, LOR=4.5, CGPA=8.87, Research=1, Chance_of_Admit=0.76),\n",
       " Row(Region='C', GRE_Score=316, TOEFL_Score=104, University_Rating=3, SOP=3.0, LOR=3.5, CGPA=8.0, Research=1, Chance_of_Admit=0.72),\n",
       " Row(Region='E', GRE_Score=322, TOEFL_Score=110, University_Rating=3, SOP=3.5, LOR=2.5, CGPA=8.67, Research=1, Chance_of_Admit=0.8),\n",
       " Row(Region='B', GRE_Score=314, TOEFL_Score=103, University_Rating=2, SOP=2.0, LOR=3.0, CGPA=8.21, Research=0, Chance_of_Admit=0.65)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create 'admission_sample_df'\n",
    "# YOUR CODE HERE\n",
    "admission_sample_df = admission_df.limit(30)\n",
    "admission_sample_df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "247f4c0aaa64fbba85f4f2e661b003d9",
     "grade": true,
     "grade_id": "cell-57638388c2ad5eb0",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# 1 pts - right number of rows\n",
    "np.testing.assert_equal(admission_sample_df.count(), 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c559cf4b7166497727bcb57c9b32e8bd",
     "grade": false,
     "grade_id": "cell-21369ae318d400ec",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**(7 pts)** Below, transform `admission_sample_df` into a Pandas dataframe and do a scatter plot of `GRE_Score` vs `TOEFL_Score`. In addition, grouping each point with different color based on `Chance_of_Admit`. If the chance over 0.6, colored the points blue; otherwise, colored the points red. Last, describe what you find? (Remember to add **axis titles**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aeacc9bfe1d258f16eaa1f74412e08f3",
     "grade": true,
     "grade_id": "cell-733193a16ed546b6",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='GRE_Score', ylabel='TOEFL_Score'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5 pts: Scatter plot of GRE_Score vs TOEFL_Score\n",
    "# YOUR CODE HERE\n",
    "\n",
    "admission_sample_df = admission_sample_df.toPandas()\n",
    "\n",
    "\n",
    "\n",
    "admission_sample_df.plot.scatter(x = 'GRE_Score', y = 'TOEFL_Score', c = 'Chance_of_Admit')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Region', 'GRE_Score', 'TOEFL_Score', 'University_Rating', 'SOP', 'LOR',\n",
       "       'CGPA', 'Research', 'Chance_of_Admit'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admission_sample_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5cebbce497e4fb9cd495a8efd39a760d",
     "grade": true,
     "grade_id": "cell-dd7a31bc0ef827f8",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# 2 pts: What you find based on the scatter plot?\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# The higher the GRE and TOEFL score, the greater chance of admission\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7ebd53bbced4b999f064706dad37dbdf",
     "grade": false,
     "grade_id": "cell-ec142e2e68de9605",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Perform correlations between SOP, LOR, and CGPA\n",
    "\n",
    "Create a `admission_corr_df` dataframe that contains the correlations between `SOP` and `LOR` as a column `corr_SOP_LOR`, between `LOR` and `CGPA` as `corr_LOR_CGPA`, and `SOP` and `CGPA` as `corr_SOP_CGPA`. (Using admission_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cb56146a17e5c327622b6f1e1760d965",
     "grade": false,
     "grade_id": "cell-df532240f4d92753",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# create 'admission_corr_df' here\n",
    "# YOUR CODE HERE\n",
    "tmp_df = admission_df.toPandas()\n",
    "\n",
    "# calculate correlations and save as variables\n",
    "sop_lor = tmp_df['SOP'].corr(tmp_df['LOR'])\n",
    "\n",
    "lor_cgpa = tmp_df['LOR'].corr(tmp_df['CGPA'])\n",
    "\n",
    "sop_cgpa = tmp_df['SOP'].corr(tmp_df['CGPA'])\n",
    "\n",
    "\n",
    "# save variables into dict\n",
    "col_names = {'corr_SOP_LOR': sop_lor,'corr_LOR_CGPA': lor_cgpa,'corr_SOP_CGPA': sop_cgpa}\n",
    "\n",
    "\n",
    "# convert dict to dataframe\n",
    "admission_corr_df = pd.DataFrame(col_names, index = [0])\n",
    "\n",
    "admission_corr_df = spark.createDataFrame(admission_corr_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b6f6eea28b7090b37cbb3c9c66b9f3f1",
     "grade": true,
     "grade_id": "cell-cc77c0b74fa5348e",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# 3 pts\n",
    "np.testing.assert_equal(set(admission_corr_df.columns), \n",
    "                        {'corr_SOP_LOR', 'corr_LOR_CGPA', 'corr_SOP_CGPA'})\n",
    "np.testing.assert_almost_equal(list(admission_corr_df.first().asDict().values()),\n",
    "                               [0.7295925366175836, 0.6702112958281646, 0.718143958057528], decimal=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c29c5107e1156893d1906558b8878af8",
     "grade": false,
     "grade_id": "cell-6a8aaa697c9bbf35",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Compute mean and standard deviation Change_of_Admit for regions\n",
    "\n",
    "Create `region_chance_df` with the column `region`, `avg_chance`, and `sd_chance`, where `avg_chance` is the average chance of admit in different regions and `sd_chance` is the standard deviation of chance of admit. Sort the resulting dataframe from highest to lowest average chance of admit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9bf6636af715d9bd16c4ac9b7e5f6b3c",
     "grade": false,
     "grade_id": "cell-adc9962ca3f172dd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Region', 'GRE_Score', 'TOEFL_Score', 'University_Rating', 'SOP', 'LOR', 'CGPA', 'Research', 'Chance_of_Admit']\n",
      "Region\n",
      "A    0.728353\n",
      "B    0.712000\n",
      "C    0.702000\n",
      "D    0.734000\n",
      "E    0.750154\n",
      "Name: Chance_of_Admit, dtype: float64\n",
      "Region\n",
      "A    0.147453\n",
      "B    0.132475\n",
      "C    0.147840\n",
      "D    0.146020\n",
      "E    0.136410\n",
      "Name: Chance_of_Admit, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "region_chance_df = pd.DataFrame()\n",
    "\n",
    "print(admission_df.columns)\n",
    "\n",
    "# group by region\n",
    "region_grp = admission_df.toPandas().groupby(['Region'])\n",
    "\n",
    "# get average chance_of_admit per region\n",
    "avg_chance_series = region_grp.mean(['Chance_of_Admit']).Chance_of_Admit\n",
    "print(avg_chance_series)\n",
    "\n",
    "# get stdev chance_of_admit per region\n",
    "stdv_chance_series = region_grp.std().Chance_of_Admit\n",
    "print(stdv_chance_series)\n",
    "\n",
    "# join two series\n",
    "region_chance_df = pd.DataFrame({'region':     avg_chance_series.index,\n",
    "                                 'avg_chance': avg_chance_series,\n",
    "                                 'sd_chance':  stdv_chance_series}).sort_values(by = ['avg_chance'])\n",
    "# convert to spark df\n",
    "region_chance_df = spark.createDataFrame(region_chance_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "42c6eedfeb2f9a67085849ddc44eada2",
     "grade": true,
     "grade_id": "cell-3e3efa19ef277303",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# 5 pts\n",
    "np.testing.assert_array_almost_equal(\n",
    "    (region_chance_df.orderBy('region').select('avg_chance').\\\n",
    "     rdd.map(lambda x: list(x.asDict().values())).collect()),\n",
    "[[0.7283529411764705],\n",
    " [0.712],\n",
    " [0.7020000000000001],\n",
    " [0.734],\n",
    " [0.7501538461538463]], decimal=3)\n",
    "\n",
    "np.testing.assert_array_almost_equal(\n",
    "    (region_chance_df.orderBy('region').select('sd_chance').\\\n",
    "     rdd.map(lambda x: list(x.asDict().values())).collect()),\n",
    "[[0.1474533587179311],\n",
    " [0.13247461571759256],\n",
    " [0.14784014630931444],\n",
    " [0.14602022038712573],\n",
    " [0.1364103678667368]], decimal=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "33d5db8971f43434dd99419e3704dea3",
     "grade": false,
     "grade_id": "cell-f1bd9070a4f4a096",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ce1b2c674f73f01533a2d819960d904b",
     "grade": false,
     "grade_id": "cell-398550c98eadbc15",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Dummy variables for region\n",
    "Create a dataframe `dummy_df` with columns `region` as dummy variables, and columns `GRE_Score`, `TOEFL_Score`, `CGPA`, `University_Rating`, and `Chance_of_Admit`. Use region B as the baselines and name the dummy variables `region_A` for region `A` and so on. The dataframe `dummy_df` should not contain the column `region` but only its dummy variable representations. **All column types should be float or integer.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "769b5022f018ff379dbc2f57c32cd0e7",
     "grade": false,
     "grade_id": "cell-db7e48e683df42e1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRE_Score              int64\n",
      "TOEFL_Score            int64\n",
      "CGPA                 float64\n",
      "University_Rating      int64\n",
      "Chance_of_Admit      float64\n",
      "Region_A               int64\n",
      "Region_C               int64\n",
      "Region_D               int64\n",
      "Region_E               int64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[GRE_Score: bigint, TOEFL_Score: bigint, CGPA: double, University_Rating: bigint, Chance_of_Admit: double, Region_A: bigint, Region_C: bigint, Region_D: bigint, Region_E: bigint]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dummy_df below\n",
    "\n",
    "# select relavent columns\n",
    "tmp_df = admission_df.toPandas()[['Region','GRE_Score','TOEFL_Score','CGPA','University_Rating','Chance_of_Admit']]\n",
    "\n",
    "# get dummy variables and drop region_b for reference\n",
    "dummy_df = pd.get_dummies(tmp_df, columns = ['Region'], dtype = int).drop(columns=['Region_B'])\n",
    "\n",
    "# check dtypes\n",
    "print(dummy_df.dtypes)\n",
    "\n",
    "# convert back to spark dataframe\n",
    "dummy_df = spark.createDataFrame(dummy_df)\n",
    "\n",
    "dummy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "08e681251ccb2ff430f5575dedc3b271",
     "grade": true,
     "grade_id": "cell-f39fae1fa71a3471",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# 5 pts\n",
    "np.testing.assert_equal(len(dummy_df.columns), 9)\n",
    "np.testing.assert_equal(dummy_df.select(fn.sum('Region_A')).first()['sum(Region_A)'], 85)\n",
    "np.testing.assert_equal(dummy_df.select(fn.sum('Region_D')).first()['sum(Region_D)'], 85)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "92b51a725e97536342f8267337dc1cf1",
     "grade": false,
     "grade_id": "cell-8cce282528966eda",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Model comparison\n",
    "\n",
    "In the next set of questions, you will use the splits below to fit, validate, and estimate the generalization error of your models. The `randomSplit` is called with a seed so that it does not change from what the professor used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "09f7584104f099b4df6ffa35060ccfe6",
     "grade": false,
     "grade_id": "cell-b08585ead9b207b9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# points in training:  227\n",
      "# points in validation:  126\n",
      "# points in testing:  47\n"
     ]
    }
   ],
   "source": [
    "training_df, validation_df, testing_df = dummy_df.randomSplit([0.6, 0.3, 0.1], seed=0)\n",
    "print(\"# points in training: \", training_df.count())\n",
    "print(\"# points in validation: \", validation_df.count())\n",
    "print(\"# points in testing: \", testing_df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f8d66ab79dcdf24c5f81fee9f4b36e39",
     "grade": false,
     "grade_id": "cell-d0b5fb8d8706846a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Propose three regression models\n",
    "\n",
    "In the next section, you will choose the best model to explain the data in `admission_df`. Select the right split of the data for the right step of the process (i.e., training, validation, and testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3062054c474545b66a732399049ed7a6",
     "grade": false,
     "grade_id": "cell-dcd785c97986afcf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Model 1: Fit model with only `GRE_Score`\n",
    "\n",
    "Create a pipeline that takes **GRE_Score** as a feature to predict **Chance_of_Admit** and fits a linear regression model. You should start your pipeline by taking the appropriate column or columns from `dummy_df`. Assign the fit pipeline transformer to `pipe_model1`. Your pipeline must have one vector assembler followed by a linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "38a5462f85e2da429c5aa44985fd390d",
     "grade": false,
     "grade_id": "cell-c57d53ae996b4bde",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Create 'pipe_model1' below\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# init vector assembler\n",
    "inputCols = ['Chance_of_Admit']\n",
    "outputCol = 'features'\n",
    "vec_ass = VectorAssembler(inputCols=inputCols, outputCol = outputCol)\n",
    "\n",
    "# init linear regression model\n",
    "labelCol = 'Chance_of_Admit'\n",
    "lr = LinearRegression(featuresCol=outputCol, labelCol=labelCol)\n",
    "\n",
    "pipe = Pipeline(stages = [vec_ass, lr])\n",
    "\n",
    "pipe_model1 = pipe.fit(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7e25e1c67814e76189a4a6ae37ee6bf0",
     "grade": true,
     "grade_id": "cell-a4893e248e800735",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# (5 pts)\n",
    "np.testing.assert_equal(type(pipe_model1.stages[0]), feature.VectorAssembler)\n",
    "np.testing.assert_equal(type(pipe_model1.stages[1]), regression.LinearRegressionModel)\n",
    "np.testing.assert_array_equal(pipe_model1.stages[1].coefficients.shape, (1,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7db4ca6b9b8ef5cffd712581320f6325",
     "grade": false,
     "grade_id": "cell-0a32f35acf305854",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Model 2: Fit model with `GRE_Score` and `TOEFL_Score`\n",
    "\n",
    "Follow the same idea as above and create a pipeline transformer `pipe_model2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c188642a605c3326448242ce9f8a2597",
     "grade": false,
     "grade_id": "cell-1d6b9d8550b155a0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# init vector assembler\n",
    "inputCols = ['GRE_Score','TOEFL_Score']\n",
    "outputCol = 'features'\n",
    "vec_ass = VectorAssembler(inputCols=inputCols, outputCol = outputCol)\n",
    "\n",
    "# init linear regression model\n",
    "labelCol = 'Chance_of_Admit'\n",
    "lr = LinearRegression(featuresCol=outputCol, labelCol=labelCol)\n",
    "\n",
    "pipe2 = Pipeline(stages = [vec_ass, lr])\n",
    "\n",
    "pipe_model2 = pipe2.fit(training_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "782baea21ff61b85fa180ef34a127f9c",
     "grade": true,
     "grade_id": "cell-8101d487ebf43e04",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# (5 pts)\n",
    "np.testing.assert_equal(type(pipe_model2.stages[0]), feature.VectorAssembler)\n",
    "np.testing.assert_equal(type(pipe_model2.stages[1]), regression.LinearRegressionModel)\n",
    "np.testing.assert_array_equal(pipe_model2.stages[1].coefficients.shape, (2,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "235be53a2ceb6affa1113f0edbcc156f",
     "grade": false,
     "grade_id": "cell-3a4584e870d7917f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Model 3: Fit model with region, GRE_Score, TOEFL_Score, CGPA, and Univeristy_Rating\n",
    "\n",
    "Follow the same idea as above and create a pipeline transformer `pipe_model3`. Remember that some features have been feature engineered. In particular, use the transformed columns in the order: region, GRE_Score, TOEFL_Score, CGPA, and Univeristy_Rating. Choose the columns from `dummy_df` appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "34ea814c7a5da239f558a32fb8e3391d",
     "grade": false,
     "grade_id": "cell-d76114eb3ef2a204",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# create `pipe_model3` below\n",
    "\n",
    "inputCols_ = dummy_df.columns\n",
    "inputCols_.remove('Chance_of_Admit')\n",
    "\n",
    "outputCol = 'features'\n",
    "vec_ass = VectorAssembler(inputCols=inputCols_, outputCol = outputCol)\n",
    "\n",
    "pipe3 = Pipeline(stages=[vec_ass, lr])\n",
    "\n",
    "pipe_model3 = pipe3.fit(training_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5bd910c7fecdadc8ed7d3625be48d8e7",
     "grade": true,
     "grade_id": "cell-3fec64f09c5f9b1a",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# (5 pts)\n",
    "np.testing.assert_equal(type(pipe_model3.stages[0]), feature.VectorAssembler)\n",
    "np.testing.assert_equal(type(pipe_model3.stages[1]), regression.LinearRegressionModel)\n",
    "np.testing.assert_array_equal(pipe_model3.stages[1].coefficients.shape, (8,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "03cb166d70623c95bd8e3926dcc93069",
     "grade": false,
     "grade_id": "cell-8ae6c91ed48801ee",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Compare models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a3cfcdda4fbb7ff90ad0f41752c2c8d2",
     "grade": false,
     "grade_id": "cell-1c77f9181d77846f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Estimate RMSE on validation data for the three models\n",
    "\n",
    "Create three dataframes `rmse1_df`, `rmse2_df`, and `rmse3_df` for models 1, 2, and 3, respectively, with only column `rmse`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "44c43910e53176dc89129126996e1c29",
     "grade": false,
     "grade_id": "cell-4868fed0a63693a8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# create rmse1_df, rmse2_df, and rmse3_df dataframes below\n",
    "# YOUR CODE HERE\n",
    "\n",
    "from pyspark.mllib.evaluation import RegressionMetrics\n",
    "\n",
    "def get_rmse(pipe_model, data_):\n",
    "    preds = pipe_model.transform(data_).select(['Chance_of_Admit','prediction']).rdd\n",
    "    rmse =  [(RegressionMetrics(preds).rootMeanSquaredError)]\n",
    "    rmse_df = pd.DataFrame(rmse, columns=['rmse'])\n",
    "    rmse_s_df = spark.createDataFrame(rmse_df)\n",
    "    return rmse_s_df\n",
    "\n",
    "\n",
    "rmse1_df, rmse2_df, rmse3_df = [get_rmse(i, validation_df) for i in [pipe_model1,pipe_model2,pipe_model3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                rmse|\n",
      "+--------------------+\n",
      "|7.623024555645947...|\n",
      "+--------------------+\n",
      "\n",
      "+-------------------+\n",
      "|               rmse|\n",
      "+-------------------+\n",
      "|0.09208178467056616|\n",
      "+-------------------+\n",
      "\n",
      "+-------------------+\n",
      "|               rmse|\n",
      "+-------------------+\n",
      "|0.07423096627523848|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# display the answers here\n",
    "rmse1_df.show()\n",
    "rmse2_df.show()\n",
    "rmse3_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8667bcddbc78ac0063269e8ec38f7bda",
     "grade": true,
     "grade_id": "cell-3b822c91b066bf09",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# (5 pts)\n",
    "np.testing.assert_equal(rmse1_df.count(), 1)\n",
    "np.testing.assert_equal(rmse2_df.count(), 1)\n",
    "np.testing.assert_equal(rmse3_df.count(), 1)\n",
    "np.testing.assert_equal(rmse1_df.columns, ['rmse'])\n",
    "np.testing.assert_equal(rmse2_df.columns, ['rmse'])\n",
    "np.testing.assert_equal(rmse3_df.columns, ['rmse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "acb1e1944cf0ec1381c9e168bcb007fe",
     "grade": false,
     "grade_id": "cell-2554e0a148260c25",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Assign the best cross validated model to a variable `best_model` below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fa884e51878e5a17c9e2290add9457d9",
     "grade": false,
     "grade_id": "cell-c90e54ce6ce997f3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# assign best model (the best pipeline transformer) to a variable best_model below\n",
    "\n",
    "best_model = pipe_model3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "02183f5be1cfa4d961324c345ebde91b",
     "grade": true,
     "grade_id": "cell-35afdf9356e2d8c0",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# (1 pts)\n",
    "np.testing.assert_equal(type(best_model), pyspark.ml.pipeline.PipelineModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "65425c746f594ab1e9ce0f8505a7d704",
     "grade": false,
     "grade_id": "cell-a99d0caf3a210263",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Estimate generalization performance with RMSE\n",
    "\n",
    "Create a variable `rmse_best_df` that contains the RMSE of the best model on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d1abdc50e622c6c1356c761b7d616188",
     "grade": false,
     "grade_id": "cell-1ecb77ce154ee874",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|               rmse|\n",
      "+-------------------+\n",
      "|0.04987463358423814|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create rmse_best_df\n",
    "\n",
    "rmse_best_df = get_rmse(best_model, testing_df)\n",
    "rmse_best_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "97b09637da7cc6b5f5feccc6984c5b9a",
     "grade": true,
     "grade_id": "cell-4d8dbfbdf95c6bc6",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# (2 pts)\n",
    "np.testing.assert_equal(rmse_best_df.count(), 1)\n",
    "np.testing.assert_equal(rmse_best_df.columns, ['rmse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5356a7b0eec1cf5398a4aafcb9b5d09d",
     "grade": false,
     "grade_id": "cell-737b6d13dffc6cd9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**(1 pts)** What is the best estimated generalization performance of the best model? Answer in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2cf756b46ea0129cd0e630946aa2fb1a",
     "grade": true,
     "grade_id": "cell-3f5687cd81273841",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# (1 pts)\n",
    "# this model generalized very well since the root mean squared error was lower in testing,\n",
    "# which means it performed better on data it had not seen before. This is a sign that the model is not\n",
    "# overfitted to the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do inference with best model\n",
    "\n",
    "Assume that model 3 is the best one. Redefine a new pipeline for this model called `pipe_model_best` and fit it to the **entire training data** (all of `dummy_df`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3c481548582d0228e36909c72d902ab6",
     "grade": false,
     "grade_id": "cell-e208c1a9d8454894",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# create `pipe_model_best` below\n",
    "# YOUR CODE HERE\n",
    "\n",
    "pipe_model_best = Pipeline(stages=[VectorAssembler(inputCols=inputCols_, outputCol='features'),\n",
    "                                  LinearRegression(featuresCol='features',labelCol='Chance_of_Admit')])\n",
    "\n",
    "pipe_model_best = pipe_model_best.fit(dummy_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6a41b48cd0aa92ed02d559a50978e9b7",
     "grade": true,
     "grade_id": "cell-2daf591ae711f6d5",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# (2 pts) check that the model was fitted correctly\n",
    "np.testing.assert_equal(type(pipe_model_best.stages[0]), feature.VectorAssembler)\n",
    "np.testing.assert_equal(type(pipe_model_best.stages[1]), regression.LinearRegressionModel)\n",
    "np.testing.assert_array_equal(pipe_model_best.stages[1].coefficients.shape, (8,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "16063f699d921a471e74c981316bafdf",
     "grade": false,
     "grade_id": "cell-d6e2ab884588f873",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**(3 pts)** Assume that all features on `dummy_df` were comparable (i.e., standardized). Taking region B as the baseline, what are the top 2 most important features for *increasing chance of admit* and the top 2 most important features for *decreasing chance of admit*? Answer below with code and comments to support your answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "526ee418f78e447d0041045b43ccdfb0",
     "grade": true,
     "grade_id": "cell-1ace5536c0322bdb",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('CGPA', 0.13657572802617515),\n",
      " ('Region_D', 0.020523195689054648),\n",
      " ('Region_C', 0.012116155680552021),\n",
      " ('University_Rating', 0.0115839403346216),\n",
      " ('Region_A', 0.005942194281988699),\n",
      " ('TOEFL_Score', 0.0026633645647471623),\n",
      " ('GRE_Score', 0.0021354520334256805),\n",
      " ('Region_E', 0.0004887804276942577)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\n    The two most important features for increasing chance of admit are CGPA and being from region D.\\nConversely, the same features that are most important for increasing admission chances are the same two features that have\\nthe most negative effect (CGPA and being from region D). For example, if you do poorly on the GRE, it won't lower your chances\\nas much as doing poorly with CGPA.\\n\\n \""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pprint \n",
    "pp = pprint.PrettyPrinter()\n",
    "\n",
    "coefs = list(zip(pipe_model_best.stages[0].getInputCols(),list(pipe_model_best.stages[1].coefficients)))\n",
    "\n",
    "coefs.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "pp.pprint(coefs)\n",
    "\n",
    "'''\n",
    "\n",
    "    The two most important features for increasing chance of admit are CGPA and being from region D.\n",
    "Conversely, the same features that are most important for increasing admission chances are the same two features that have\n",
    "the most negative effect (CGPA and being from region D). For example, if you do poorly on the GRE, it won't lower your chances\n",
    "as much as doing poorly with CGPA.\n",
    "\n",
    " '''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
