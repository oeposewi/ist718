{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3e32afc3220521fd5a9bbff4cec73b63",
     "grade": false,
     "grade_id": "cell-ade2cf06b0fbd2b9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# IST 718: Big Data Analytics\n",
    "\n",
    "- Professor: Daniel Acuna <deacuna@syr.edu>\n",
    "\n",
    "## General instructions:\n",
    "\n",
    "- You are welcome to discuss the problems with your classmates but __you are not allowed to copy any part of your answers either from your classmates or from the internet__\n",
    "- You can put the homework files anywhere you want in your https://jupyterhub.ischool.syr.edu/ workspace but _do not change_ the file names. The TAs and the professor use these names to grade your homework.\n",
    "- Remove or comment out code that contains `raise NotImplementedError`. This is mainly to make the `assert` statement fail if nothing is submitted.\n",
    "- The tests shown in some cells (i.e., `assert` and `np.testing.` statements) are used to grade your answers. **However, the professor and TAs will use __additional__ test for your answer. Think about cases where your code should run even if it passess all the tests you see.**\n",
    "- Before downloading and submitting your work through Blackboard, remember to save and press `Validate` (or go to \n",
    "`Kernel`$\\rightarrow$`Restart and Run All`). \n",
    "- Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the packages needed for this part\n",
    "# create spark and sparkcontext objects\n",
    "from pyspark.sql import SparkSession\n",
    "import numpy as np\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "from pyspark.ml import feature\n",
    "from pyspark.ml import regression\n",
    "from pyspark.sql import functions as fn\n",
    "from pyspark.sql import Row\n",
    "from pyspark import sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6b22b37e081fca4745ce97cf6952e9dc",
     "grade": false,
     "grade_id": "cell-08055393264a3d49",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Warning: Use exclusively Spark. Do not use Pandas at all in this assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "687516ecd6d856d5a93742443ec210b6",
     "grade": false,
     "grade_id": "cell-923bede0f3e1d4cd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Part 2: Dataframes and Spark ML\n",
    "\n",
    "In this section, you will learn to create dataframes from messy data and then perform simple regression on it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a9a9a67555ab717c03ff4f70a31b8445",
     "grade": false,
     "grade_id": "cell-4a3c1e56d6d249d5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "There is some mysterious process generating data, stored in `/datasets/host_server_requests`, with the following format:\n",
    "\n",
    "`feature1|feature2|...|featurem => outcome`\n",
    "\n",
    "`feature1` can be either \"HOST\" or \"SERVER\" and from feature $2$ through $m$ are floating point numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "31da6ddec218fff221f2d8257f2b31a5",
     "grade": false,
     "grade_id": "cell-957fbfa010a6000e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "requests_rdd = sc.textFile(\"host_server_requests.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "72fac1ed218f635c993838bd5b195d12",
     "grade": false,
     "grade_id": "cell-839c115f722f63c2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 1:\n",
    "\n",
    "In this question, you will create a function `process_line` that receives a line from `/datasets/host_server_requests` and returns a `Row` object with the following columns: \n",
    "\n",
    "- You will codify the first feature as a column `f1` with a `1` if the source is `HOST` and `0` otherwise\n",
    "- You will create 7 other features that you assign to columns `f2`, `f3`, ..., through `f8`\n",
    "- Finally, you will assign the outcome to the column `label`\n",
    "- Remember to make all features of type `float`.\n",
    "\n",
    "For the following code:\n",
    "\n",
    "\n",
    "```python\n",
    "requests_rdd.map(process_line).take(10)\n",
    "```\n",
    "\n",
    "it should generate the following:\n",
    "\n",
    "```python\n",
    "[Row(f1=1.0, f2=2e-05, f3=0.80279, f4=-0.09174, f5=0.04041, f6=-0.22504, f7=-0.0504, f8=0.58149, label=163.877101489),\n",
    " Row(f1=1.0, f2=5e-05, f3=-0.00454, f4=-0.0211, f5=0.00174, f6=-0.11684, f7=0.19182, f8=-0.23745, label=-105.023368852),\n",
    " Row(f1=1.0, f2=0.00015, f3=-0.10437, f4=0.04869, f5=0.18333, f6=-0.21864, f7=0.27638, f8=-0.13441, label=-115.011801582),\n",
    " Row(f1=1.0, f2=-0.00015, f3=0.27118, f4=0.14526, f5=0.06101, f6=0.13401, f7=0.06237, f8=-0.74065, label=-122.623452696),\n",
    " Row(f1=1.0, f2=-6e-05, f3=0.1413, f4=0.12084, f5=0.05452, f6=0.09272, f7=0.2534, f8=-0.65331, label=-117.130523174),\n",
    " Row(f1=1.0, f2=-8e-05, f3=-0.41534, f4=-0.04205, f5=-0.00724, f6=-0.07463, f7=0.13273, f8=0.19112, label=-73.5775668047),\n",
    " Row(f1=1.0, f2=-8e-05, f3=-0.45937, f4=-0.23509, f5=-0.05679, f6=0.06077, f7=-0.49597, f8=-0.30668, label=-137.37933148),\n",
    " Row(f1=0.0, f2=2e-05, f3=-0.23465, f4=0.07345, f5=-0.07217, f6=-0.19256, f7=-0.14377, f8=-0.15183, label=-162.804738349),\n",
    " Row(f1=0.0, f2=-7e-05, f3=-0.10321, f4=0.27467, f5=0.04058, f6=-0.24541, f7=0.08631, f8=-0.2979, label=-212.111291232),\n",
    " Row(f1=1.0, f2=-7e-05, f3=-0.01039, f4=-0.00453, f5=-0.01352, f6=-0.05199, f7=-0.3772, f8=-0.19641, label=-91.5022329392)]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "679006b9ba5e584a9549de3d5a0908e8",
     "grade": false,
     "grade_id": "cell-acec0ed673c71bec",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def process_line(line):    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try it here\n",
    "requests_rdd.map(process_line).take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "276f108d65eeaa2c1e3b8c811ac3cfcb",
     "grade": true,
     "grade_id": "cell-89d70831d5dc6e1c",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# 5 pts\n",
    "np.testing.assert_equal(len(requests_rdd.map(process_line).first()), 9)\n",
    "np.testing.assert_equal(requests_rdd.map(process_line).count(), 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2:\n",
    "\n",
    "Transform the `requests_rdd` RDD into a Spark 2.0 DataFrame and store it in `requests_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d1b0054c79694af274ba1579f3826f42",
     "grade": false,
     "grade_id": "cell-d3e65de380d61134",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# create requests_df variable here\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1290dcae61e376310c8da70f2bcc4c16",
     "grade": true,
     "grade_id": "cell-362523b107452045",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# 5 pts\n",
    "np.testing.assert_equal(type(requests_df), sql.dataframe.DataFrame)\n",
    "np.testing.assert_equal(set(requests_df.columns), {'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'label'})\n",
    "np.testing.assert_equal(requests_df.count(), 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3:\n",
    "\n",
    "In this question, we will explore the data. We have a hypothesis that depending on whether the request was from the \"HOST\" or \"SERVER\" (`f1` column), there are significant difference in the outcome (`label` column).\n",
    "\n",
    "You will find whether this is true by computing two quantities for each group of `f1`. You will compute the mean outcome, the count of each group and the *standard error of the mean* or SE of the outcome. The equation for SE of a variable $x$ is:\n",
    "\n",
    "$$\\text{SE}(x) = \\frac{\\text{std}(x)}{\\sqrt{n}}$$\n",
    "\n",
    "From `requests_df`, create a dataframe `summary_df` that contains, for each value of `f1`, the mean `label` as a column `mlabel`, the count `label`as a column `clabel`, and the SEM of `label` as a column `semlabel`. For the SE equation, use the *sample standard devivation* computed by `fn.stddev_samp`. **Hint: perform an aggregate operation and use appropriate combinations of functions in the package `fn`. Rename columns appropriately**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f51f62572111fb7416abe94da8b6e335",
     "grade": false,
     "grade_id": "cell-3d19258199b8a93d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# create the dataframe `summary_df` below\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The schema of `summary_df` should look like:\n",
    "\n",
    "```python\n",
    "summary_df.printSchema()\n",
    "```\n",
    "```console\n",
    "root\n",
    " |-- f1: double (nullable = true)\n",
    " |-- mlabel: double (nullable = true)\n",
    " |-- clabel: long(nullable = false)\n",
    " |-- semlabel: double (nullable = true)\n",
    "\n",
    "```\n",
    "The mean label for each `f1` feature should be:\n",
    "\n",
    "```python\n",
    "summary_df.select('f1', 'mlabel').show()\n",
    "```\n",
    "\n",
    "```console\n",
    "+---+------------------+\n",
    "| f1|            mlabel|\n",
    "+---+------------------+\n",
    "|0.0|-29.61175341232892|\n",
    "|1.0|-12.62243193686321|\n",
    "+---+------------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "661768df6156209e1cc184b1db6f6a22",
     "grade": true,
     "grade_id": "cell-62d3e583f4017e21",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# 5 pts\n",
    "np.testing.assert_equal(summary_df.count(), 2)\n",
    "np.testing.assert_equal(set(summary_df.columns), {'f1', 'mlabel', 'clabel', 'semlabel'})\n",
    "np.testing.assert_approx_equal(summary_df.rdd.map(lambda r: r.mlabel).sum(), -42.23418534919212,\n",
    "                              significant=3)\n",
    "np.testing.assert_approx_equal(summary_df.rdd.map(lambda r: r.semlabel).sum(), 3.503568410619124,\n",
    "                              significant=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4:\n",
    "\n",
    "Use the transformer `VectorAssembler` to create a dataframe that puts all columns `f1`, `f2`, ..., `f8` from `requests_df` into a column named `features`. Assign the vector assembler object into a variable `var` and the new dataframe into the variable  `features_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d0c4919fa8e008bde1fde280e99e5521",
     "grade": false,
     "grade_id": "cell-b1f11325408fb1ce",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The schema of the new dataframe should be like this:\n",
    "\n",
    "```python\n",
    "features_df.printSchema()\n",
    "```\n",
    "\n",
    "```console\n",
    "root\n",
    " |-- f1: double (nullable = true)\n",
    " |-- f2: double (nullable = true)\n",
    " |-- f3: double (nullable = true)\n",
    " |-- f4: double (nullable = true)\n",
    " |-- f5: double (nullable = true)\n",
    " |-- f6: double (nullable = true)\n",
    " |-- f7: double (nullable = true)\n",
    " |-- f8: double (nullable = true)\n",
    " |-- label: double (nullable = true)\n",
    " |-- features: vector (nullable = true)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try it here\n",
    "features_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "18db619b447231f272243029a4a63479",
     "grade": true,
     "grade_id": "cell-50ebf2b6919fad92",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# 5 pts\n",
    "np.testing.assert_equal(type(features_df), sql.dataframe.DataFrame)\n",
    "np.testing.assert_equal(set(features_df.columns), \n",
    "                        {'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'features', 'label'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "633222c8b745fdd2228639f36a150730",
     "grade": false,
     "grade_id": "cell-3054385622721159",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 5:\n",
    "\n",
    "Run a linear regression model on `features_df` using the `features` column to predict the `label` column. Store the transformer fit to the data in the `lr_model` variable (the transformer is what the estimator's `fit` function returns). Use the transformer to create a dataframe named `predictions_df` with two columns: `label` and `prediction` based on the `features_df` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ba7304999d1a342f5627b41dbfa1c4da",
     "grade": false,
     "grade_id": "cell-fa0a9a7a314d8b51",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# create the linear regression estimator below and name it lr_model.\n",
    "# use the model to create the dataframe predictions_df with two columns label and prediction\n",
    "# by transforming the dataframe `features_df` \n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting dataframe should be in `predictions_df`. Running `predictions_df.show(5)` should produce something like\n",
    "\n",
    "```python\n",
    "predictions_df.show(5)\n",
    "```\n",
    "\n",
    "```console\n",
    "+--------------+-------------------+\n",
    "|         label|         prediction|\n",
    "+--------------+-------------------+\n",
    "| 163.877101489| 159.06994708337518|\n",
    "|-105.023368852| -99.52598722329135|\n",
    "|-115.011801582|-109.91382979074436|\n",
    "|-122.623452696|-118.62864861627764|\n",
    "|-117.130523174|-116.89245751669506|\n",
    "+--------------+-------------------+\n",
    "only showing top 5 rows\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f383c20b03ef892c4f8c91d912c1da88",
     "grade": true,
     "grade_id": "cell-117a01b0fbecc285",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# 10 pts:\n",
    "np.testing.assert_equal(set(predictions_df.columns), {'label', 'prediction'})\n",
    "np.testing.assert_equal(predictions_df.count(), 10000)\n",
    "np.testing.assert_equal(type(lr_model), regression.LinearRegressionModel)\n",
    "np.testing.assert_equal(type(var), feature.VectorAssembler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "22cc68225580587db33a2f5a6ca24ce6",
     "grade": false,
     "grade_id": "cell-b3cddc65c26cd3c4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 6:\n",
    "\n",
    "Try to get the R squared and adjusted R squared of the linear model by `model.summary` and assign in variable `r2` and `adj_r2`. Also, based on the `predictions_df` dataframe, count how many rows which the difference between prediction and label are greater than 5. Assign the count into `diff_5`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "513a8a9be982130b83133e8e15945c14",
     "grade": false,
     "grade_id": "cell-ee9ac076ea123c1c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "57c93d6ae45cba264daf340ed90d3d15",
     "grade": true,
     "grade_id": "cell-c8d5da8c2f729244",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# 5 pts:\n",
    "np.testing.assert_approx_equal(r2, 0.9952916629913636, significant=3)\n",
    "np.testing.assert_approx_equal(adj_r2, 0.9952878929287003, significant=3)\n",
    "assert diff_5 == 5617"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7:\n",
    "\n",
    "Root Mean Square Error(RMSE) and Mean Absolute Error(MAE) are common metrics to evaluate regression model. \\\n",
    "The root mean squared error is defined as\n",
    "\n",
    "$$ \\text{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^n (\\hat{y}_i - y_i)^2}$$\n",
    "\n",
    "and the mean absolute error is defined as\n",
    "\n",
    "$$ \\text{MAE} = \\frac{1}{n} \\sum_{i=1}^n \\left\\lvert \\hat{y}_i - y_i \\right\\rvert$$\n",
    "\n",
    "Combine functions in `fn` package and other functions to create a dataframe called `lr_metrics_df` that contains the root mean squared error in column `rmse` and the mean absolute error in column `mae` based on the `predictions_df` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "878beeafe97112f69bcb9801a2f5592e",
     "grade": false,
     "grade_id": "cell-324e29f1a0af77af",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# define the `lr_metrics_df` dataframe here\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0a9967717e559b923a29f78e1f2f8d6b",
     "grade": true,
     "grade_id": "cell-a1ce5f770004bf22",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# 10 pts\n",
    "np.testing.assert_array_less(lr_metrics_df.first().rmse, 10)\n",
    "np.testing.assert_array_less(lr_metrics_df.first().mae, 10)\n",
    "np.testing.assert_equal(lr_metrics_df.count(), 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
